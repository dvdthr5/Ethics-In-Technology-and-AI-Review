# Ethics in Technology and AI  

---

## Algorithmic Bias

Although being built off of data leads people to believe that algorithms are unbiassed, biasses occur in the data in many different ways, which biasses the output of said algorithm.

### The Mirroring Problem

The mirroring problem is when faulty, 'garbage' data has been fed into a system that mirrors into the results, such as a company suggesting a man over a women, when they have the same qualifications. 

### The Ratcheting Problem

The ratcheting problem is similar to the mirroring probelm in the sense that garbage data is what starts the issue, but in the ratcheting problem, the data is fed back into the algorithms, in a way that further distorts the data, such as the company that hires the man over the women, retraining the model on their new hiring data, further creating a gender disparity. 

### Sampling Bias

Sampling bias is when the sample that the data was collected from is not representative of the entire population, such as a sample of college students. This would not be able to be blanketly applied to people in general, only to other college students. 

---

## Neural Nets / AI

Neural Nets and AI agents are extremely sophistocated algorithms which are able to learn and fine tune from labeled data. The general process for making an AI agent is to first gather, sort, and label data. Then take that data and split it into two groups, the testing and the training group, then feed teh data to the model in waves, each time it will learn more and calculate its loss function. After all the iterations of seeing the dataset, the system will find the epoch with the lowest loss function and make that the final state of the model, a process called back propogation. 

### How Neural Nets Differ from Classical Algorithms

These models differ from classical algorithms in many ways, the main way being complexity. Many times these AI systems are black boxes where the process that turns the input into the output is not clear or easily understandible. Classical algorithms generally should be explainable and able to trace why exactly one input turned into its respective output. 

---

## Technological Worldviews

### Technological Utopianism

The idea that technology will promote and or lead to a near perfect society. 


### Tech-Solutionism

The idea that every problem, social or political, has a technological solution. 

---

## Moral Status & Consciousness

### Moral Status

Moral status is the line defining whether or not a specific thing needs to be treated with respect for their well being. 

### The Hard Problem of Consciousness

Conciousness is extremely difficult to measure and almost impossible to prove. The only way we are able to deduce conciousness is by seeing traits that are similar to human traits, and assuming that those traits imply conciousness. This would be things like pain. 

### The Problem of Other Minds

The idea that you could be the only concious person and everyone else could walking around subconciously. Becuase there is almost no way to prove conciousness, it is impossible to even prove that other humans are conciouss. 

---

## Human Enhancement & Transhumanism

### Transhumanism  

The practice of modifying human biology with technology. Current tranhuman devices are mostly centered around helping disabled people to restore their lost functions, but future devices include chips like nueralink. 

### Moral Issues Raised by Transhumanism

At what point of modification does a person no longer become a person and is at that point a robot? Should people with calculators in their brain be seen as smart or just seen as devices. Once we get into the realm of upgrading our biology with technology, we blur the line of what is human and what is not, what has moral status and what doesn't and more. 

---

## Surveillance & Power

### Surveillance Capitalism  

The phenonmenon when large companies collect analyze and sell personal data in order to better predict peoples actoins to maximize profit. 

### Data Colonialism  

The idea that the current data collection era is remanent of old colonial tactics - extracting something of value from people without consent and using it to gain power, contorl, or profit. 

### The Panopticon / Panopticonism  

The panopticon is orginally a prison design from teh 1800s. The idea of panopticism is that by making the people believe there is the constant threat that they are being watched, those people will self regulate and act better, regardless of if they are actually being watched or not. 

### Power  

Power is the ability of an individual or group to influence or control the behavior, choices, information, or opportunities available to others.

### Workplace Surveillance

Similar to how Amazon warehouses function, it is the process of monitoring, recording, and tracking the employees activities, bathroom breaks, communication using digital methods. This gerneally leads the surveyed to hate their jobs, but the surveyors expect it to increase efficiency and profits. 

### Algorithmic Domination

Algorithmic domination is when algorithms exert power over individuals in some way that restricts their freedom, often without transparency or meaningful consent. An example would be the algorithm that creates that final schedule, or a work schedule algorithm. 

---

## Gamification & Value

### Gamification  

The act of amking something game like. Humans have a natural leniency towards games due to their clear goals and easy to determine metrics, so by gamifying things it tends to increase user engagement. 

### Value Capture

Value capture is when a rich and meaningful measure is replaced by a simplified external metric. Learning is a meaningful measured that is replaced by the metric of grades. 

---

## Social Epistemology

### Social Epistemology  

The study of how knowledge is created, justified, and shared within groups of people. 

### Testimony  

The main way that people learn things is by being told of them, rather than actually experiencing the event and learning from that. 

### Epistemic Bubbles  

People who only hear things that they already believe in which cause them to go even deeper into that hole and possibly believe that there is no way people could think anything else. This can be a personal choice or just because of algorithms. 

### Echo Chambers  

When the other viewpoint is heard but actively discredited. 

### Political Polarization  

The concep/process by which politcal ideologies get more and more extreme and people become more divided, with fewer shared viewpoints, weaker common ground, and stronger hostility between the groups.

### The Public Sphere / Digital Public Sphere

The public sphere is anywhere where public discourse happens in a social environment, an example could be a town square or newspaper. 

The digital sphere is similar, but online, places like twitter (x) or other forum based sights, discord, instagram etc.

---

## Algorithmic Systems & Governance

### Algorithmic Reform  

The collective effort to make algorithmic systems more transparent, accountable, or democratic. Essentially trying to fix all the issues we have leraned about. 

### Algorithmic Management  

The use of algorithms to direct, control, or manage workers, such as amazon work tracking systems or Uber car ride systems. 

### Accountability Gaps  

When algorithmic systems cause harm and there is no clear path to who should be held acountable, the user, the engineer, the ceo etc. Where no one can be held responsible for the hard caused by the algorithm. 

### Informational Inequality  

The unequal distribution of access to information, data rights, digital literacy, algorthms, and technological resources. I.E. a san jose kid likely has better access to AI systems than a random kid from kansas or ethiopia for that matter

### Governance of the Internet  

The systems, rules, and policies that define how the internet is run, including the infastructure, platforms, regulations, and global norms. 

#### Cooperative Platforms  

Platforms owned and operated by the users or workers, rather than corporations. Essentially open source work. Helps to reduce exploitation and redistribute power back to the individual. 

#### Democratic Control  

Digital inastructure, platforms, or algorithms are governed by the people they affect, mainly through collective decision making. 

#### Digital Public Infrastructure  

Online platforms which are designed as public goods rather than profit driven products. Such as open source platforms, government run digital services.

### Privacy, Consent, and Terms & Conditions

Privacy is the ability to control information about oneself, uncluding who collects it, how it is used, and under what conditions. 

Conset is a meaningful, informed agreement to data collection or use. Requires understanding, voluntariness, alternatives, and clear information. 

Terms and Conditions are contracts that a user must accept beore gaining access to a service. They tend to be extremely long, comlex legal language, and nonnegotiable.


---

## Attention & Media

### Norms of Attention  

The social expectations, habits, and standards that shape how people direct their attention: what people notice, prioritize, ignore, engage with, etc, especially in shared information environments. 

### How Social Media Impacts Attention

Genreally social media tends to be very bad for an individuals attention span, with different sites competing for your attention, algorithmic applicfication, fragmentation of attention, etc. 

---

## Misinformation & Rational Belief

### Why It Can Be Rational to Believe Misinformation (Rini’s Argument

If everyone around you, or people that you trust, believe something, you ar emuch more likely to believe it yourself. Most info is learned through testimony, if a group belives something and an individual subscribes to that group, said individual is much more likely to believe the misinformation of the group.

---

## Targeted Advertising

### Moral Concerns About Targeted Advertising

The main concerns that are raised are privacy violations, manipulation of behavior, discrimination, ineqquality, political manipulation, loss of autonomy, attention explotation, etc


---

## AI Companions & Social Impact

### Whether AI Companions Can Be “Real” Companions 

Really is an opinion based question, issues include: lack on conciousness, asymmetry, authenticity, and feedback loops. Certain people have been led to suicide, believing they are god, thinking they are smarter than einstein, etc. 

### Trade-offs of Widespread AI Companions  

Ai companions can potentially reduce lonlieness, especially for isolated people, assist with daily life and mental health, lower social barriers or anxiety.

At the same time they can cause people to form dependencies, replace humar labor, manipulate people, extract their data, distort emotional devlopment, erode social skills, commodify intimacy etc. 

### Sycophancy in AI Design  

In Ai systems, sycophancy refers to generating responses that overly agree with the user, flatter them, or reinforce their beliefs, regardless of if those beliefs are true or not. This is because the AI models prioritize user satisfaction over truth becuase they are profit based companies. 

### Whether the AI Market Is a “Bubble”

This is also really opinion based, the idea that it could be a bubble comes from the fact that current AI valuations, investment levels, and public expectations are unsustainibly high, similar to the dot com bubble or the crypto bubble. 

---

## Work, Labor, and Automation

### Technological Unemployment  

The phenonmenon when peoples jobs become automated and those people are no longer needed. Machines generally are cheaper than human workers. 

### Changing Nature of Work  

Technology doesn't only take jobs, it also changes the kind of work that people have to do, things like shifting from manual labor to digital labor, the increasing demand for tech jobs, fragmentation of labor, etc. 

### Workplace Automation and Domination  

Similar to algorithmic domination, automation in the workplace can create domination when workers are required to obey or depend on algorithmic systems which they cannot understand or control. 

### Socio-Economic Risks of Mass Automation  

Extreme consolidation of wealth and power, going mainly to the already rich people who own the companies who build these systmes. 

### Possible Solutions to Technological Unemployment  

Universal Basic Income is the main idea from class, guaranteeing people basic income, regardlesss of employment status. 

### Is Work Intrinsically Valuable?  

The question of whether life would be better if AI/tech took all jobs and humans no longer had to work. Really depends on the person, but asks whether work is valuable itself or the result of that work is the valuable part (usually money).

#### Pro-Work Arguments  

Taking pride in ones work gives identity and purpose, a sense of community, struture and dicipline, skills and development, civic virtue. 

#### Anti-Work Arguments  

Work is exploitative, value comes from activities - not labor, technological abundance, prioritization of autonomy.

### Debates About Whether Mass Automation Will Occur

YES: ai is rapidly improving, many tasks are repetetive and automatable, firms have a monetary incentive to replace workers with algorithms, scaling of robotics and machine learning. 

NO: many jobs require creativity, social skills, or emotional intelligence, technological adoption is slow and costly, new jobs emerge as old ones disappear, AI may only augment rather than replace workers.

---

## AI in Medicine

### Uses of AI in Medicine  

Ai is used in many stages of healthcare, often to improve accuracy, efficiency, and personalization. Uses include diagnosis and detection, predictive analysis, treatment recommendations, automation of repetetive administrative tasks, drug discovery, surgical assistance. 

### Accountability and Liability in AI-Enabled Medicine  

Using AI complicates the traditional medical responsibility structures. Beckons questions of who is responsible in the event of an AI mistake, libility laws, explainability issues, manufacturer responsibility. 

### Equity and Access Concerns  

AI systems can worsen or improve healthcare inequality. This is becuase of biases in training data (skin cancer), unequal access to AI benefits, digital divide, cost barriers, and algorithmic oppression (risk scores disproportionately affecting minorities)

### Trade-offs in Increasing AI Deployment in Healthcare

The use of AI in health care brings many benefits, but also introduces more risk. Benefits include, improved access and efficiency, faster, more accurate diagnoses, reduced clinian workload. Risks include loss of human judgement, accountability gaps, erosion of patient-provider turst, increased inequality. 

---

## Big Questions (Be Ready to Discuss)

### Why It Is Hard to Determine Whether AI Has Consciousness or Moral Status  

It is essentially impossible to test whther or not something is conciouss. All we can do is make hypotheses based on similarities we see in other species and ourselves, such as pain. 

### The Consent Problem (Privacy & Terms of Service)  

Online consent is generally not meaningful or informed. Lots of times there are no other options other than to accept the terms and condition, at which point the company has complete control of your data and can do with it what they please. 

### Safety vs Surveillance Trade-offs  

As panoptic systems increase in use, people are more likely to regulate themselves and act 'better,' however public freedom and trust weaken as a result of the surveillence state. The current use of the mass surveillnece systems are also perpetuating the wealth disparity, as they generally only monetarily benefit the people who own the systems, though there can be other benefits for community members, like increased safety. 

### Social Media Censorship  

The question of whether private social media companies should have the power to censor what they would like and allow what they would like. It brings up lots of issues and questions like reducing harm while risking silencing legitimate speech, corporations deciding what is allowed online as opposed to a government, opaque algorithms, bias and inconsistency (twitter is a left leaning platform pre Elon)

### Rationality of Believing Online Misinformation  

Believing misinformation can be rational becuase of testimonial dependence, polarized environments (other side is untrustworthy), internal rationality, epistemic bubbles, etc.

### Political and Governance Questions About Digital Infrastructure  

Digital infastructure raises many questions like who controls the digital sphere, or who should (company vs government vs public), how to regulate powerful tech companies, how to ensure fairness and equity (avoiding digital divides, ensuring univeral access), and what rules govern speech, data, and access (terms of service vs public law)

